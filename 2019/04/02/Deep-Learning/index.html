<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Knowledge is Bulletproof."><title>Deep-Learning | Feng Talk</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Deep-Learning</h1><a id="logo" href="/.">Feng Talk</a><p class="description">Life, Technology and More</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Deep-Learning</h1><div class="post-meta">Apr 2, 2019</div><div class="post-content"><a id="more"></a>
<h3 id="0-Symbol"><a href="#0-Symbol" class="headerlink" title="0. Symbol"></a>0. Symbol</h3><p>$ n $: dimension of x</p>
<p>$ m $: number of samples</p>
<p>$i$: index of samples</p>
<p>$x^{(i)}$: the $x$ of $i^{th}$ sample</p>
<p>$ \alpha $: learning rate</p>
<h3 id="1-Binary-Classification"><a href="#1-Binary-Classification" class="headerlink" title="1. Binary Classification"></a>1. Binary Classification</h3><h4 id="a-Logistic-Regression"><a href="#a-Logistic-Regression" class="headerlink" title="a.Logistic Regression:"></a>a.Logistic Regression:</h4><script type="math/tex; mode=display">
\hat{y} = P(y = 1| x)</script><p>where we want $ 0\leq \hat{y} \leq 1 $.</p>
<p>we can use sigmoid function:</p>
<script type="math/tex; mode=display">
\hat{y} = \sigma(\omega x + b)</script><p>where</p>
<script type="math/tex; mode=display">
\sigma(z) = \frac{1}{1 + e^{-z}}</script><p>To write a common format of activation function $z$, we set $ \Theta $ as follow:</p>
<script type="math/tex; mode=display">
\Theta = 
\begin{bmatrix}
\theta_0 \\
\theta_1 \\
.\\
.\\
.\\
\theta_{n_x}
\end{bmatrix}</script><p>where $ \theta_0 $ is $ b $, </p>
<p>the matrix </p>
<script type="math/tex; mode=display">
\begin{bmatrix}
\theta_1 \\
.\\
.\\
.\\
\theta_{n_x}
\end{bmatrix}</script><p>is $\omega $.</p>
<p>We can write our active function $z$ as $ \Theta^{T}x $</p>
<p>So, the final logistic regression can written as:</p>
<script type="math/tex; mode=display">
\hat{y}^{(i)} = \sigma(\Theta^{T}x^{(i)})</script><h4 id="b-Cost-function"><a href="#b-Cost-function" class="headerlink" title="b. Cost function"></a>b. Cost function</h4><script type="math/tex; mode=display">
L(\hat{y}, y) = -(y\log{\hat{y}} + (1 - y)\log{(1 - \hat{y})})</script><p>If $y = 1$, $L(\hat{y}, y) = -\log{\hat{y}}$ and we want lower loss,  $\hat{y}$ will close to 1.</p>
<p>If $y = 0$, $L(\hat{y}, y) = -\log{(1-\hat{y})}$ and we want lower loss, $\hat{y}$ will close to 0.</p>
<p>So, $L(\hat{y}, y)$ can be used as loss function.</p>
<p>Then, we can get the cost function from the cost function:</p>
<script type="math/tex; mode=display">
\begin{aligned}

J(\Theta) 
&= \frac{1}{m}\sum^{m}_{i = 1}L(\hat{y}, y)\\
&= -\frac{1}{m}\sum^{m}_{i = i}[y^{(i)}\log{\hat{y}^{(i)}} + (1 - y^{(i)})\log{(1 - \hat{y}^{(i)}})] 
\end{aligned}</script><h4 id="c-Conclusion"><a href="#c-Conclusion" class="headerlink" title="c. Conclusion"></a>c. Conclusion</h4><p>Logistic Regression:</p>
<script type="math/tex; mode=display">
\hat{y}^{(i)} = \sigma(\Theta^{T}x^{(i)})</script><p>Loss function:</p>
<script type="math/tex; mode=display">
L(\hat{y}, y) = -(y\log{\hat{y}} + (1 - y)\log{(1 - \hat{y})})</script><p>Cost function:</p>
<script type="math/tex; mode=display">
J(\Theta) = -\frac{1}{m}\sum^{m}_{i = i}[y^{(i)}\log{\hat{y}^{(i)}} + (1 - y^{(i)})\log{(1 - \hat{y}^{(i)}})]</script><h3 id="2-Gradient-Descent"><a href="#2-Gradient-Descent" class="headerlink" title="2. Gradient Descent"></a>2. Gradient Descent</h3><p>Repeat {</p>
<p>$\omega = \omega - \alpha\frac{\partial J(\omega, b)}{\partial \omega}$;</p>
<p>$b = b - \alpha\frac{\partial J(\omega, b)}{\partial b}$;</p>
<p>}</p>
<p>当 $\omega$ 和 $b$ 的值几乎不变时，说明到达了最低点。</p>
<p>此时的 $\omega$ 和 $b$ 则是我们需要的最优解。</p>
<h4 id="3-How-to-calculate-the-gradient-descent"><a href="#3-How-to-calculate-the-gradient-descent" class="headerlink" title="3. How to calculate the gradient descent"></a>3. How to calculate the gradient descent</h4><h5 id="Calculate-the-derivation-of-L-hat-y-y"><a href="#Calculate-the-derivation-of-L-hat-y-y" class="headerlink" title="Calculate the derivation of $L(\hat{y}, y)$"></a>Calculate the derivation of $L(\hat{y}, y)$</h5><p>Firstly ,we calculate $ \frac{\partial L(\hat{y}, y)}{\partial \hat{y}} $:</p>
<script type="math/tex; mode=display">
\frac{\partial L(\hat{y}, y)}{\partial \hat{y}} = -\frac{y}{\hat{y}} + \frac{1-y}{1-\hat{y}}</script><p>Then, we calculate $\frac{\partial \hat{y}}{\partial z}$:</p>
<script type="math/tex; mode=display">
\frac{\partial \hat{y}}{\partial z} = \hat{y} (1 - \hat{y})</script><p>Finally, we can get $ \frac{\partial L(\hat{y}, y)}{\partial z }$ :</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial L(\hat{y}, y)}{\partial z} 
&= \frac{\partial L(\hat{y}, y)}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z} \\
&= (-\frac{y}{\hat{y}} + \frac{1-y}{1-\hat{y}}) \cdot (\hat{y} (1 - \hat{y})) \\
&= \hat{y} - y
\end{aligned}</script><p>Then, we can get $\frac{\partial L(\hat{y}, y)}{\partial w_i}$:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial L(\hat{y}, y)}{\partial w_i} 
&=  \frac{\partial L(\hat{y}, y)}{\partial z}\cdot \frac{\partial z}{\partial w_i}\\
&= (\hat{y} - y)x_i
\end{aligned}</script><h5 id="Calculate-the-derivation-of-J-w-b"><a href="#Calculate-the-derivation-of-J-w-b" class="headerlink" title="Calculate the derivation of $J(w, b)$"></a>Calculate the derivation of $J(w, b)$</h5><script type="math/tex; mode=display">
\frac{\partial}{\partial w_i} J(w,b) = \frac{1}{m} \sum_{i = 1}^{m} \frac{\partial}{\partial w_i} L(\hat{y}^{(i)},y^{(i)})</script><p>Algorithm to calculate it:</p>
<p>$J=0;\partial w_1 = 0; \partial w_2 = 0; …;\partial w_n = 0 $</p>
<p>$For\ i = 0\ to\ m: $</p>
<script type="math/tex; mode=display">
z^{(i)} = w^T x^{(i)} + b\\
a^{(i)} = \sigma(z^{(i)}) \\
J+= -[y^{(i)} log{a^{(i)}} + (1 - y^{(i)})log{(1 - a^{(i)})}] \\
\partial z^{(i)} = a^{(i)} - y^{(y)} \\
\partial w_1 += x^{(i)}_1 \partial z^{(i)} \\
\partial w_2 += x^{(i)}_2 \partial z^{(i)} \\
\partial w_3 += x^{(i)}_3 \partial z^{(i)} \\
.\\
.\\
.\\
\partial w_n = x^{(i)}_n \partial z^{(i)}\\
\partial b += \partial x^{(i)}</script><p>$J /= m; \partial w_1 /= m; \partial w_1 /= m; \partial w_2 /= m;…;\partial w_n /= m$</p>
<p>After computing the $\frac{\partial}{\partial w_i} J(w,b)$, we can do the gradient descent</p>
<p>Repeat {</p>
<p>​    $\omega = \omega - \alpha\frac{\partial J(\omega, b)}{\partial \omega}$;</p>
<p>​    $b = b - \alpha\frac{\partial J(\omega, b)}{\partial b}$;    </p>
<p>}</p>
<p>in each repeat, we need calculus $\frac{\partial J}{\partial w}$ and $\frac{\partial J}{\partial b}$ </p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Author: </strong>absolutelycold</li><li class="post-copyright-link"><strong>Blog Link: </strong><a href="/2019/04/02/Deep-Learning/">https://absolutelycold.github.io/2019/04/02/Deep-Learning/</a></li><li class="post-copyright-license"><strong>Copyright Declaration: </strong>Feng Talk, https://absolutelycold.github.io</li></ul></div><br><div class="tags"><a href="/tags/Deep-Learning/">Deep-Learning</a></div><div class="post-nav"><a class="pre" href="/2019/04/23/JAVA-Learning/">JAVA SE Note</a><a class="next" href="/2019/03/24/Socket-Programming-in-C/">Socket Programming in C</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C-Language/">C Language</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/JAVA/">JAVA</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep-Learning</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/socket/" style="font-size: 15px;">socket</a> <a href="/tags/programming/" style="font-size: 15px;">programming</a> <a href="/tags/java-notes/" style="font-size: 15px;">java notes</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/04/23/JAVA-Learning/">JAVA SE Note</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/02/Deep-Learning/">Deep-Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/24/Socket-Programming-in-C/">Socket Programming in C</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Feng Talk.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>